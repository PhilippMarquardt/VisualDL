{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualdl.models.hrnet import HRNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df036a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HRNetV2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a94cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .visualdl import vdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdl.train(r\"E:\\source\\repos\\VisualDL\\visualdl\\trainer\\segmentation\\segmentation.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weightpath, imgs, confidence = 0.45):\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=weightpath, force_reload=True)\n",
    "    size = imgs[0].shape[0]\n",
    "    model.conf = confidence\n",
    "    preds = model(imgs, size=size)\n",
    "    finals = []\n",
    "    for cnt, img in enumerate(imgs):\n",
    "        tmp = []\n",
    "        boxes = preds.xyxy[cnt]\n",
    "        for box in boxes:\n",
    "            middlex = int(box[0] + (box[2] - box[0]) / 2)\n",
    "            middley = int(box[1] + (box[3] - box[1]) / 2)\n",
    "            data = list(box.detach().cpu().numpy())\n",
    "            data.append((middlex, middley))\n",
    "            tmp.append(tuple(data))\n",
    "        finals.append(tmp)\n",
    "    return finals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from visualdl import vdl\n",
    "imgs = [cv2.imread(r\"F:\\source\\repos\\Daten\\ObjectDetection\\Her1\\train\\images\\PD-L1=2_0_41328-42312_75.png\")[..., ::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = vdl.get_inference_model(r\"F:\\source\\repos\\hsayolo\\runs\\train\\exp5\\weights\\001.pt\", type=\"od\")\n",
    "model1.predict(imgs, confidence = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4e792",
   "metadata": {},
   "source": [
    "# OD Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(r\"F:\\source\\repos\\Daten\\Cells\\valid\\labels\\05__1_4735_9814.png\", 0) * 255\n",
    "orig = cv2.imread(r\"F:\\source\\repos\\Daten\\Cells\\valid\\images\\05__1_4735_9814.png\", 0)\n",
    "dist = cv2.distanceTransform(mask, cv2.DIST_L2, 5)\n",
    "#cv2.peak_local_max(dist, indices=False, min_distance=20,#\n",
    "\tlabels=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5805fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"xd.png\", dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa3d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc534c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981e3a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ca17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cv2.imread(r\"F:\\source\\repos\\Daten\\FinalHer2512\\train\\labels\\05__1_4369-9252_12.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_li = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4760913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in os.listdir(r\"F:\\source\\repos\\Daten\\FinalHer2512\\valid\\labels\"):\n",
    "    unique_li.extend(np.unique(cv2.imread(os.path.join(r\"F:\\source\\repos\\Daten\\FinalHer2512\\valid\\labels\", im))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_li = list(set(unique_li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b75ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(r\"F:\\source\\repos\\Daten\\FinalHer2512\\valid\\labels\"):\n",
    "    im = cv2.imread(os.path.join(r\"F:\\source\\repos\\Daten\\FinalHer2512\\valid\\labels\", image))\n",
    "    im[im == 9] = 2\n",
    "    im[im == 10] = 3\n",
    "    im[im == 11] = 4\n",
    "    im[im == 12] = 5\n",
    "    cv2.imwrite(os.path.join(r\"F:\\source\\repos\\Daten\\FinalHer2512\\valid\\labels\", image), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b720c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_li.index(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e00ea7",
   "metadata": {},
   "source": [
    "# BUBUBU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\phili\\Downloads\\watershed_coins_01.jpg\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b55bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ddbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e556ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43294f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualdl.inference.inference import ModelInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac52c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelInference(r\"F:\\source\\repos\\VisualDL\\runs\\exp103\\weights\\best.pt\", type=\"od\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725321de",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(r\"F:\\source\\repos\\VisualDL\\runs\\exp103\\weights\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = attempt_load(r\"F:\\source\\repos\\VisualDL\\runs\\exp103\\weights\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebf788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
