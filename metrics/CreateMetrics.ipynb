{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd367a2",
   "metadata": {},
   "source": [
    "# General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe5a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from visualdl import vdl\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "pred = vdl.get_inference_model(r\"C:\\Users\\philmarq\\source\\repos\\VisualDL\\megfinalglyphe\\efficientnet-b7, UnetPlusPlus.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c32c67",
   "metadata": {},
   "source": [
    "## Create metrics with visualdl models segmentation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119d9db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Check the output directory for results.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sliding_window_inference(model, image, window_size=1024, overlap=0.5):\n",
    "    h, w = image.shape[:2]\n",
    "    stride = int(window_size * (1 - overlap))\n",
    "    \n",
    "    # Initialize accumulator for logits and counter for averaging\n",
    "    nc = 2  # number of classes - adjust as needed\n",
    "    logits_acc = np.zeros((nc, h, w), dtype=np.float32)\n",
    "    count_acc = np.zeros((h, w), dtype=np.float32)\n",
    "    \n",
    "    # Pad image if needed\n",
    "    pad_h = (window_size - h % window_size) % window_size\n",
    "    pad_w = (window_size - w % window_size) % window_size\n",
    "    padded_image = cv2.copyMakeBorder(image, 0, pad_h, 0, pad_w, cv2.BORDER_REFLECT)\n",
    "    \n",
    "    # Sliding window inference\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            # Extract window\n",
    "            window = padded_image[y:y+window_size, x:x+window_size]\n",
    "            if window.shape[:2] != (window_size, window_size):\n",
    "                continue\n",
    "                \n",
    "            # Get prediction for window\n",
    "            window_pred = model.predict([window], single_class_per_contour=False, return_logits=True)\n",
    "            \n",
    "            # Add to accumulator\n",
    "            y_end = min(y + window_size, h)\n",
    "            x_end = min(x + window_size, w)\n",
    "            window_h, window_w = y_end - y, x_end - x\n",
    "            \n",
    "            logits_acc[:, y:y_end, x:x_end] += window_pred[:, :window_h, :window_w]\n",
    "            count_acc[y:y_end, x:x_end] += 1\n",
    "    \n",
    "    # Average the logits\n",
    "    count_acc = np.maximum(count_acc, 1)\n",
    "    for c in range(nc):\n",
    "        logits_acc[c] /= count_acc\n",
    "        \n",
    "    # Get final prediction\n",
    "    final_pred = np.argmax(logits_acc, axis=0)\n",
    "    return final_pred\n",
    "\n",
    "def create_overlay(original_img, mask, alpha=0.5, color=[255, 0, 0]):\n",
    "    \"\"\"Create an overlay of the mask on the original image\"\"\"\n",
    "    overlay = np.zeros_like(original_img)\n",
    "    overlay[mask > 0] = color  # Apply the specified color for positive regions\n",
    "    return cv2.addWeighted(original_img, 1-alpha, overlay, alpha, 0)\n",
    "\n",
    "def calculate_iou(pred, target):\n",
    "    \"\"\"Calculate Intersection over Union\"\"\"\n",
    "    intersection = np.logical_and(pred, target).sum()\n",
    "    union = np.logical_or(pred, target).sum()\n",
    "    return intersection / (union + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "def plot_confusion_matrix(cm, output_path):\n",
    "    \"\"\"Plot confusion matrix using seaborn\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate all metrics and return as dictionary\"\"\"\n",
    "    # Convert to binary (0 or 1)\n",
    "    y_true_bin = y_true > 0\n",
    "    y_pred_bin = y_pred > 0\n",
    "    \n",
    "    # Flatten arrays\n",
    "    y_true_flat = y_true_bin.flatten()\n",
    "    y_pred_flat = y_pred_bin.flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_true_flat, y_pred_flat)\n",
    "    iou = calculate_iou(y_pred_bin, y_true_bin)\n",
    "    precision = precision_score(y_true_flat, y_pred_flat)\n",
    "    recall = recall_score(y_true_flat, y_pred_flat)\n",
    "    f1 = f1_score(y_true_flat, y_pred_flat)\n",
    "    \n",
    "    # Calculate additional metrics from confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    \n",
    "    return {\n",
    "        'IoU': iou,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Specificity': specificity,\n",
    "        'Confusion Matrix': cm\n",
    "    }\n",
    "\n",
    "# Main execution\n",
    "base = r\"C:/Users/philmarq/source/repos/Daten/datasetmegfinal/dataset/valid/images\"\n",
    "label_base = r\"C:/Users/philmarq/source/repos/Daten/datasetmegfinal/dataset/valid/labels\"\n",
    "output_dir = \"outputallsecond\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize aggregated metrics\n",
    "all_metrics = []\n",
    "\n",
    "# Create metric output files\n",
    "metrics_file = os.path.join(output_dir, 'metrics.txt')\n",
    "aggregate_metrics_file = os.path.join(output_dir, 'aggregate_metrics.txt')\n",
    "\n",
    "for file in os.listdir(base):\n",
    "    image_path = os.path.join(base, file)\n",
    "    label_path = os.path.join(label_base, file)\n",
    "    \n",
    "\n",
    "    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    orig_img = cv2.imread(image_path)\n",
    "    \n",
    "\n",
    "    preds = sliding_window_inference(pred, img, window_size=1024, overlap=0.0)\n",
    "    preds = preds * 50\n",
    "    \n",
    "\n",
    "    label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "    label *= 50\n",
    "    \n",
    "\n",
    "    metrics = calculate_metrics(label, preds)\n",
    "    all_metrics.append(metrics)\n",
    "    \n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        metrics['Confusion Matrix'],\n",
    "        os.path.join(output_dir, f'confusion_matrix_{os.path.splitext(file)[0]}.png')\n",
    "    )\n",
    "    \n",
    "\n",
    "    with open(metrics_file, 'a') as f:\n",
    "        f.write(f\"\\nMetrics for {file}:\\n\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            if metric_name != 'Confusion Matrix':\n",
    "                f.write(f\"{metric_name}: {value:.4f}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    pred_overlay = create_overlay(orig_img.copy(), preds > 0, alpha=0.25, color=[255, 0, 0])\n",
    "    truth_overlay = create_overlay(orig_img.copy(), label > 0, alpha=0.25, color=[0, 255, 0])\n",
    "    \n",
    "    preds_colored = cv2.cvtColor(preds.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "    label_colored = cv2.cvtColor(label.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    combined_img = cv2.hconcat([preds_colored, label_colored, pred_overlay, truth_overlay])\n",
    "    cv2.imwrite(os.path.join(output_dir, file), combined_img)\n",
    "\n",
    "\n",
    "with open(aggregate_metrics_file, 'w') as f:\n",
    "    f.write(\"Aggregate Metrics (Mean ± Std):\\n\")\n",
    "    for metric in ['IoU', 'Precision', 'Recall', 'F1-Score', 'Accuracy', 'Specificity']:\n",
    "        values = [m[metric] for m in all_metrics]\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        f.write(f\"{metric}: {mean_val:.4f} ± {std_val:.4f}\\n\")\n",
    "\n",
    "print(\"Processing complete. Check the output directory for results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f8646",
   "metadata": {},
   "source": [
    "# Extract information from model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9f30f",
   "metadata": {},
   "source": [
    "## print all custom data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ac9d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'structure_indices': [2, 3],\n",
       " 'image_size': 1024,\n",
       " 'modeltype': 'Full Image',\n",
       " 'object_based': False,\n",
       " 'physical_tile_size': '(226.388852600035',\n",
       " '226.388852600035)': None,\n",
       " 'project_type': 'dummy',\n",
       " 'pyramid_level': 0,\n",
       " 'datetime': '21/01/2022 15:33',\n",
       " 'structures': 'Glomerulus',\n",
       " 'objects_count': 312,\n",
       " 'model': \"[{'backbone': 'efficientnet-b7', 'decoder': 'UnetPlusPlus'}]\",\n",
       " 'files': {'File': ['05_.czi',\n",
       "   '06_.czi',\n",
       "   '07_.czi',\n",
       "   '12_.czi',\n",
       "   '13_.czi',\n",
       "   '14_.czi',\n",
       "   '17_.czi',\n",
       "   '18_.czi',\n",
       "   '19_.czi',\n",
       "   '05_.czi',\n",
       "   '06_.czi',\n",
       "   '07_.czi',\n",
       "   '12_.czi',\n",
       "   '13_.czi',\n",
       "   '14_.czi',\n",
       "   '17_.czi',\n",
       "   '18_.czi',\n",
       "   '19_.czi'],\n",
       "  'Scene': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]},\n",
       " 'calculate_weight_map': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.state[\"custom_data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9021a4",
   "metadata": {},
   "source": [
    "## access string which actually creates the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0445e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smp.create_model(arch=\"UnetPlusPlus\", encoder_name=\"efficientnet-b7\", encoder_weights=\"imagenet\", in_channels=3, classes = 2)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.state[\"model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e106d2",
   "metadata": {},
   "source": [
    "## access metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4613f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'model', 'has_distance_map', 'validation_metrics', 'train_metrics', 'custom_data'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f2bbdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9950659871101379,\n",
       " 'IoU': 0.9320716857910156,\n",
       " 'train_loss': 0.018424429236223328}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.state[\"train_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42b33078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9778851866722107,\n",
       " 'IoU': 0.7717246413230896,\n",
       " 'validation_monitor_metric': 0.7717246413230896,\n",
       " 'validation_loss': 0.11256959306245501}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.state[\"validation_metrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25325d6",
   "metadata": {},
   "source": [
    "# Convert to yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d11cae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "def convert_data_to_yaml(\n",
    "    custom_data: Dict[str, Any],\n",
    "    training_info: Dict[str, Any],\n",
    "    training_settings: Dict[str, Any]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert model data to YAML format using custom_data and two additional JSON objects.\n",
    "    \n",
    "    Args:\n",
    "        custom_data (Dict[str, Any]): Dictionary containing model custom data\n",
    "        training_info (Dict[str, Any]): Dictionary containing training information\n",
    "        training_settings (Dict[str, Any]): Dictionary containing training settings\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted YAML string\n",
    "    \"\"\"\n",
    "    yaml_dict = {\n",
    "        'model_name': training_settings.get('meta_data', {}).get('name', 'No Information!'),\n",
    "        'trainer_name': 'No Information!',\n",
    "        'training_date': training_info.get('creation_date', 'No Information!'),\n",
    "        'model_metadata': {\n",
    "            'name': training_settings.get('meta_data', {}).get('name', 'No Information!'),\n",
    "            'lib': 'VisualDL',\n",
    "            'training_information': {\n",
    "                'creation_date': training_info.get('creation_date', 'No Information!'),\n",
    "                'completion_date': training_info.get('completion_date', 'No Information!'),\n",
    "                'system_information': training_info.get('system_information', {\n",
    "                    'os': 'No Information!',\n",
    "                    'cpu': 'No Information!',\n",
    "                    'gpu': 'No Information!',\n",
    "                    'ram': 'No Information!'\n",
    "                }),\n",
    "                'training_status': training_info.get('training_status', 'No Information!'),\n",
    "                'error_message': training_info.get('error_message', '')\n",
    "            },\n",
    "            'training_settings': {\n",
    "                'project_id': training_settings.get('project_id', 'No Information!'),\n",
    "                'project_type': training_settings.get('project_type', custom_data.get('project_type', 'No Information!')),\n",
    "                'meta_data': training_settings.get('meta_data', {\n",
    "                    'name': 'No Information!',\n",
    "                    'version': '',\n",
    "                    'description': '',\n",
    "                    'is_new_model': True\n",
    "                }),\n",
    "                'dataset_parameters': training_settings.get('dataset_parameters', {\n",
    "                    'dataset_approach': 2,\n",
    "                    'dataset_type': 0,\n",
    "                    'dataset_only': False,\n",
    "                    'use_existing_dataset': False\n",
    "                }),\n",
    "                'training_parameters': training_settings.get('training_parameters', {\n",
    "                    'epochs': 100,\n",
    "                    'early_stopping': 500,\n",
    "                    'batch_size': 2,\n",
    "                    'metrics': [0],\n",
    "                    'loss_functions': [0, 1],\n",
    "                    'optimizer': 1,\n",
    "                    'learning_rate': 0.0001\n",
    "                }),\n",
    "                'model_parameters': training_settings.get('model_parameters', {\n",
    "                    'description': 'No Information!',\n",
    "                    'version': 'No Information!',\n",
    "                    'creation_date': 'No Information!',\n",
    "                    'completion_date': 'No Information!',\n",
    "                    'dataset_type': 0,\n",
    "                    'input_channels': 3,\n",
    "                    'fluorescence_channels': [],\n",
    "                    'spatial_dims': 2,\n",
    "                    'image_width': custom_data.get('image_size', 'No Information!'),\n",
    "                    'image_height': custom_data.get('image_size', 'No Information!'),\n",
    "                    'number_of_classes': len(custom_data.get('structure_indices', ['No Information!'])),\n",
    "                    'pyramid_level': custom_data.get('pyramid_level', 'No Information!')\n",
    "                })\n",
    "            },\n",
    "            'structures': training_settings.get('structures', []),\n",
    "            'training_computer_name': 'Unknown',\n",
    "            'raw_custom_data': custom_data\n",
    "        },\n",
    "        'hsa_kit_metadata': {\n",
    "            'version': '0.0.0.0',\n",
    "            'hsa_user_name': 'Unknown'\n",
    "        },\n",
    "        'gtds': [],\n",
    "        'description_version': custom_data.get('datetime', 'No Information!')\n",
    "    }\n",
    "    \n",
    "    return yaml.dump(yaml_dict, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20be2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data = vdl.get_inference_model(r\"C:\\Users\\philmarq\\source\\repos\\VisualDL\\custom_experiments\\HyperNetNonVessel\\001.pt\").state[\"custom_data\"]\n",
    "\n",
    "\n",
    "with open(r\"C:\\Users\\philmarq\\source\\repos\\VisualDL\\custom_experiments\\HyperNetNonVessel\\training_information.json\", 'r') as file:\n",
    "    training_information = json.load(file)  \n",
    "    \n",
    "with open(r\"C:\\Users\\philmarq\\source\\repos\\VisualDL\\custom_experiments\\HyperNetNonVessel\\training_settings_config.json\", 'r') as file:\n",
    "    training_settings_config = json.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b79415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yml = convert_data_to_yaml(custom_data, training_information, training_settings_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc5bbe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_name: HyperNetNonVessel\\ntrainer_name: No Information!\\ntraining_date: \\'2023-02-14T14:26:00\\'\\nmodel_metadata:\\n  name: HyperNetNonVessel\\n  lib: VisualDL\\n  training_information:\\n    creation_date: \\'2023-02-14T14:26:00\\'\\n    completion_date: \\'2023-02-14T14:26:00\\'\\n    system_information:\\n      os: No Information!\\n      cpu: No Information!\\n      gpu: No Information!\\n      ram: No Information!\\n    training_status: finished\\n    error_message: \\'\\'\\n  training_settings:\\n    project_id: 00000000-0000-0000-0000-000000000000\\n    project_type: AnnotationTool (Generic)\\n    meta_data:\\n      name: HyperNetNonVessel\\n      version: \\'\\'\\n      description: \\'\\'\\n      is_new_model: true\\n    dataset_parameters:\\n      dataset_approach: 2\\n      dataset_type: 2\\n      dataset_only: false\\n      use_existing_dataset: false\\n    training_parameters:\\n      epochs: 100\\n      early_stopping: 500\\n      batch_size: 2\\n      metrics:\\n      - 0\\n      loss_functions:\\n      - 0\\n      - 1\\n      optimizer: 1\\n      learning_rate: 0.0001\\n    model_parameters:\\n      description: HSA-AI dataset\\n      version: \\'1.0\\'\\n      creation_date: \\'\\'\\n      completion_date: \\'\\'\\n      dataset_type: 2\\n      input_channels: 3\\n      fluorescence_channels: []\\n      spatial_dims: 2\\n      image_width: 512\\n      image_height: 512\\n      number_of_classes: 3\\n      pyramid_level: 3\\n  structures:\\n  - id: 1\\n    label: Non Vessel\\n    is_structure: true\\n    color: \\'#e6194b\\'\\n    is_dynamic: true\\n    parent_id: null\\n    same_level_rank: 0\\n    is_unfolded: true\\n    annotations_are_visible: true\\n    has_children: true\\n    nesting_depth: 0\\n    total_object_count: 1\\n    tool_settings: null\\n    optional_params: null\\n  - id: 2\\n    label: Ery Vessel\\n    is_structure: true\\n    color: \\'#e6194b\\'\\n    is_dynamic: true\\n    parent_id: null\\n    same_level_rank: 0\\n    is_unfolded: true\\n    annotations_are_visible: true\\n    has_children: true\\n    nesting_depth: 0\\n    total_object_count: 1\\n    tool_settings: null\\n    optional_params: null\\n  training_computer_name: Unknown\\n  raw_custom_data:\\n    structure_indices:\\n    - 2\\n    - 1\\n    image_size: 512\\n    dataset_approach: Sliding Window\\n    used_fluorescence_channels: []\\n    modeltype: segmentation\\n    physical_tile_size: !!python/tuple\\n    - 226.34881912390307\\n    - 226.34881912390307\\n    pyramid_level: 3\\n    physicalSize: 4.4208753735137316e-07\\n    physicalSizeUnit: \"\\\\xB5m\"\\n    project_type: dummy\\n    datetime: 14/02/2023 14:26\\n    structures: Non Vessel, Ery Vessel\\n    objects_count: 408\\n    model: \\'[{\\'\\'backbone\\'\\': \\'\\'tu-resnest50d\\'\\', \\'\\'decoder\\'\\': \\'\\'Unet\\'\\'}]\\'\\n    files:\\n      File:\\n      - 05_48h_Gr1T11.czi\\n      - 07_4h_Gr2T4.czi\\n      - 09_1h_Gr2T3.czi\\n      - 13_4h_Gr3T4.czi\\n      - 14_1h_Gr3T2.czi\\n      - 14_4h_Gr3T5.czi\\n      - 16_48h_Gr3T10.czi\\n      - 17_48h_Gr3T11.czi\\n      - 05_48h_Gr1T11.czi\\n      - 07_4h_Gr2T4.czi\\n      - 09_1h_Gr2T3.czi\\n      - 13_4h_Gr3T4.czi\\n      - 14_1h_Gr3T2.czi\\n      - 14_4h_Gr3T5.czi\\n      - 16_48h_Gr3T10.czi\\n      - 17_48h_Gr3T11.czi\\n      Scene:\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n      - 2\\n    calculate_weight_map: false\\nhsa_kit_metadata:\\n  version: 0.0.0.0\\n  hsa_user_name: Unknown\\ngtds: []\\ndescription_version: 14/02/2023 14:26\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d07fc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.yaml', 'w') as file:\n",
    "    file.write(yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78094c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
